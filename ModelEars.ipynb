{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam, RMSprop, Adadelta, Adagrad\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.load(\"X_train_1375_0.npy\")\n",
    "Y_train = np.load(\"Y_train_1375_0.npy\")\n",
    "\n",
    "X_dev = np.load(\"X_dev_1375.npy\")\n",
    "Y_dev = np.load(\"Y_dev_1375.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545, 5511, 101)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(input_shape):\n",
    "    \"\"\"\n",
    "    Function creating the model's graph in Keras.\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Step 1: CONV layer (≈4 lines)\n",
    "    X = Conv1D(196, kernel_size=2, strides=1)(X_input)                                 # CONV1D\n",
    "    X = BatchNormalization()(X)                                 # Batch normalization\n",
    "    X = Activation('relu')(X)                                 # ReLu activation\n",
    "    X = Dropout(0.5)(X)                                 # dropout (use 0.8)\n",
    "\n",
    "        # Step 1: CONV layer (≈4 lines)\n",
    "    X = Conv1D(196, kernel_size=12, strides=4)(X)                                 # CONV1D\n",
    "    X = BatchNormalization()(X)                                 # Batch normalization\n",
    "    X = Activation('relu')(X)                                 # ReLu activation\n",
    "    X = Dropout(0.5)(X)                                 # dropout (use 0.8)\n",
    "    \n",
    "    # Step 2: First GRU Layer (≈4 lines)\n",
    "    X = GRU(units = 128, return_sequences = True)(X) # GRU (use 128 units and return the sequences)\n",
    "    X = Dropout(0.5)(X)                                 # dropout (use 0.8)\n",
    "    X = BatchNormalization()(X)                                 # Batch normalization\n",
    "    \n",
    "    # Step 3: Second GRU Layer (≈4 lines)\n",
    "    X = GRU(units = 128, return_sequences = True)(X)   # GRU (use 128 units and return the sequences)\n",
    "    X = Dropout(0.5)(X)                                 # dropout (use 0.8)\n",
    "    X = BatchNormalization()(X)                                  # Batch normalization\n",
    "    X = Dropout(0.5)(X)                                  # dropout (use 0.8)\n",
    "    \n",
    "    # Step 4: Time-distributed dense layer (≈1 line)\n",
    "    X = TimeDistributed(Dense(1, activation = \"sigmoid\"))(X) # time distributed  (sigmoid)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = 5511 # The number of time steps input to the model from the spectrogram\n",
    "n_freq = 101 # Number of frequencies input to the model at each time step of the spectrogram\n",
    "model = model(input_shape = (Tx, n_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        (None, 5511, 101)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 5510, 196)         39788     \n",
      "_________________________________________________________________\n",
      "batch_normalization_118 (Bat (None, 5510, 196)         784       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 5510, 196)         0         \n",
      "_________________________________________________________________\n",
      "dropout_148 (Dropout)        (None, 5510, 196)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 1375, 196)         461188    \n",
      "_________________________________________________________________\n",
      "batch_normalization_119 (Bat (None, 1375, 196)         784       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 1375, 196)         0         \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        (None, 1375, 196)         0         \n",
      "_________________________________________________________________\n",
      "gru_61 (GRU)                 (None, 1375, 128)         124800    \n",
      "_________________________________________________________________\n",
      "dropout_150 (Dropout)        (None, 1375, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat (None, 1375, 128)         512       \n",
      "_________________________________________________________________\n",
      "gru_62 (GRU)                 (None, 1375, 128)         98688     \n",
      "_________________________________________________________________\n",
      "dropout_151 (Dropout)        (None, 1375, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_121 (Bat (None, 1375, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_152 (Dropout)        (None, 1375, 128)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_31 (TimeDis (None, 1375, 1)           129       \n",
      "=================================================================\n",
      "Total params: 727,185\n",
      "Trainable params: 725,889\n",
      "Non-trainable params: 1,296\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = RMSprop(lr=0.1, rho=0.9, epsilon=1e-07)\n",
    "#opt = Adadelta(lr=0.01, rho=0.95, epsilon=1e-07)\n",
    "#opt = Adagrad(0.01, 0.1,  1e-6)\n",
    "#opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 545 samples, validate on 135 samples\n",
      "Epoch 1/30\n",
      "545/545 [==============================] - 917s 2s/step - loss: 0.3736 - accuracy: 0.9101 - val_loss: 0.3192 - val_accuracy: 0.9335\n",
      "Epoch 2/30\n",
      "180/545 [========>.....................] - ETA: 12:01 - loss: 0.3634 - accuracy: 0.9028"
     ]
    }
   ],
   "source": [
    "model_total = model.fit(X_train, Y_train, batch_size = 10, epochs=30, validation_data=(X_dev, Y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ml2_tr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_dev, Y_dev)\n",
    "print(\"Dev set accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_triggerword(filename):\n",
    "    plt.subplot(2, 1, 1)\n",
    "\n",
    "    x = graph_spectrogram(filename)\n",
    "    print(x)\n",
    "    print(x.shape)\n",
    "    # the spectogram outputs (freqs, Tx) and we want (Tx, freqs) to input into the model\n",
    "    x  = x.swapaxes(0,1)\n",
    "    print(x.shape)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    print(x.shape)\n",
    "    predictions = model.predict(x)\n",
    "    print(predictions)\n",
    "    print(Y_dev)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(predictions[0,:,0])\n",
    "    plt.ylabel('probability')\n",
    "    plt.show()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chime_file = \"chime.wav\"\n",
    "def chime_on_activate(filename, predictions, threshold):\n",
    "    audio_clip = AudioSegment.from_wav(filename)\n",
    "    chime = AudioSegment.from_wav(chime_file)\n",
    "    Ty = predictions.shape[1]\n",
    "    # Step 1: Initialize the number of consecutive output steps to 0\n",
    "    consecutive_timesteps = 0\n",
    "    # Step 2: Loop over the output steps in the y\n",
    "    for i in range(Ty):\n",
    "        # Step 3: Increment consecutive output steps\n",
    "        consecutive_timesteps += 1\n",
    "        # Step 4: If prediction is higher than the threshold and more than 75 consecutive output steps have passed\n",
    "        if predictions[0,i,0] > threshold and consecutive_timesteps > 75:\n",
    "            # Step 5: Superpose audio and background using pydub\n",
    "            audio_clip = audio_clip.overlay(chime, position = ((i / Ty) * audio_clip.duration_seconds)*1000)\n",
    "            # Step 6: Reset consecutive output steps to 0\n",
    "            consecutive_timesteps = 0\n",
    "        \n",
    "    audio_clip.export(\"chime_output.wav\", format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import IPython\n",
    "from td_utils import *\n",
    "%matplotlib inline\n",
    "\n",
    "filename = \"train_2.wav\"\n",
    "prediction = detect_triggerword(filename)\n",
    "chime_on_activate(filename, prediction, 0.5)\n",
    "IPython.display.Audio(\"./chime_output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
